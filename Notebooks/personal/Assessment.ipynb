{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "%cd ~/Dropbox/CanvasHacks\n",
    "\n",
    "#Plotting \n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "import datetime\n",
    "\n",
    "from CanvasHacks import environment\n",
    "from CanvasHacks.Api.RequestTools import *\n",
    "from CanvasHacks.Api.UrlTools import *\n",
    "from CanvasHacks.Configuration import InteractiveConfiguration\n",
    "# import CanvasHacks.GradingTools as GT\n",
    "# import CanvasHacks.DownloadProcessingTools as PT\n",
    "\n",
    "# File system\n",
    "from CanvasHacks.TimeTools import getDateForMakingFileName\n",
    "from CanvasHacks.Files.FileTools import  create_folder, makeDataFileIterator\n",
    "from CanvasHacks.Files.JournalsFileTools import get_journal_folders, make_folder_list, calculate_journal_counts\n",
    "from CanvasHacks.Files.QuizReportFileTools import sort_frames_by_age, get_newest_data\n",
    "\n",
    "# from CanvasHacks.JournalsFileTools import journal_folder_name, create_folder\n",
    "# from CanvasHacks.FileTools import getDateForMakingFileName\n",
    "\n",
    "# Canvas api\n",
    "from canvasapi import Canvas\n",
    "from canvasapi.quiz import QuizReport, Quiz\n",
    "from canvasapi.requester import Requester\n",
    "from canvasapi.conversation import Conversation\n",
    "\n",
    "# Initialize a Canvas api objects\n",
    "canvas = Canvas(environment.CONFIG.canvas_url_base, environment.CONFIG.canvas_token)\n",
    "requester = Requester(environment.CONFIG.canvas_url_base, environment.CONFIG.canvas_token)\n",
    "\n",
    "# Configuration\n",
    "from CanvasHacks.Definitions.skaa import Review, InitialWork, MetaReview\n",
    "from CanvasHacks.Definitions.unit import Unit #Assignment\n",
    "\n",
    "# Exceptions\n",
    "# from CanvasHacks.Errors.review_associations import AlreadyAssigned, SubmissionIncomplete\n",
    "\n",
    "# Models\n",
    "from CanvasHacks.Models.student import Student\n",
    "from CanvasHacks.Models.student import student_from_canvas_user, ensure_student\n",
    "\n",
    "# Repos\n",
    "from CanvasHacks.Repositories.DataManagement import DataStore\n",
    "from CanvasHacks.Repositories.quizzes import QuizRepository, ReviewRepository\n",
    "from CanvasHacks.Repositories.codes import AccessCodeRepo\n",
    "from CanvasHacks.Repositories.reviewer_associations import assign_reviewers, AssociationRepository\n",
    "from CanvasHacks.Repositories.students import StudentRepository\n",
    "\n",
    "# Storage\n",
    "from CanvasHacks.DAOs.sqlite_dao import SqliteDAO\n",
    "\n",
    "# Widgets\n",
    "from CanvasHacks.Widgets.ConsolidatedTextOutput import make_assignment_header, make_consolidated_text_fields\n",
    "from CanvasHacks.Widgets.InputFields import make_course_ids_input, make_canvas_token_input, make_canvas_url_input, make_general_reset_button\n",
    "from CanvasHacks.Widgets.AssignmentSelection import make_assignment_chooser, view_selected_assignments, view_ungraded_assignments\n",
    "from CanvasHacks.Widgets.LiveSelection import make_test_selector\n",
    "from CanvasHacks.Widgets.AssignmentSelection import make_unit_chooser\n",
    "\n",
    "# Plotting\n",
    "from CanvasHacks.Text.VisualizationTools import rotate_x_labels\n",
    "# from CanvasHacks.Repositories.quizzes import fix_forgot_answers\n",
    "\n",
    "import inspect\n",
    "def look_inside(obj):\n",
    "    print(inspect.getmembers(obj, lambda a:not(inspect.isroutine(a))))\n",
    "    \n",
    "    \n",
    "SEMESTER_NAME = 'S20'\n",
    "LOC = '{}/Box Sync/TEACHING/Phil 305 Business ethics/Phil305 S20'.format(environment.ROOT)# placeholder for where the access codes are stored\n",
    "ACCESS_CODES_FP = \"{}/{}-assignment-access-codes.xlsx\".format(LOC, SEMESTER_NAME)\n",
    "    \n",
    "    \n",
    "# LIKERT_PLOT_ORDER = ['Forgot', 'Strongly disagree', 'Disagree', 'Agree', 'Strongly agree']\n",
    "# LIKERT_NUM_MAP = {'Forgot' : 0, 'Strongly disagree': 1, 'Disagree': 2, 'Agree': 3, 'Strongly agree': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_test_selector()\n",
    "make_unit_chooser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.CONFIG.course_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word count of assignments vs historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire, clean, and store text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CanvasHacks.Assessment.api import get_all_essay_assigns_for_class, store_course_essays\n",
    "courses_to_get = [  ]\n",
    "\n",
    "# for cid in courses_to_get:\n",
    "#     store_course_journals(cid, 'S19')\n",
    "\n",
    "# es = get_all_essay_assigns_for_class(environment.CONFIG.course_ids[0], term='S20')\n",
    "# es\n",
    "# for cid in environment.CONFIG.course_ids:\n",
    "# store_course_essays(environment.CONFIG.course_ids[0], 'S20', start_week=12)\n",
    "\n",
    "for cid in environment.CONFIG.course_ids:\n",
    "    store_course_essays(cid, 'S20', start_unit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and store wordbags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from CanvasHacks.Assessment.processing import process_essay_entries\n",
    "from CanvasHacks.Assessment.files import EssayFiles\n",
    "\n",
    "file_handler = EssayFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "fiter = filename_handler.make_content_file_iterator()\n",
    "existing = filename_handler.bag_files\n",
    "# makeDataFileList(filename_maker.bag_folder_root)\n",
    "\n",
    "while True:\n",
    "    with open(next(fiter), 'r') as f:\n",
    "        print(\"Processing \", f.name.split('/')[-1:])\n",
    "        entries = json.load(f)\n",
    "        process_essay_entries(entries, existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from CanvasHacks.Assessment.store import load_stored_bags, EssayAssignment, JournalAssignment, TermUnitStore, TermWeekStore, TokenFiltrationMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def load_stored_bags(file_handler):\n",
    "#     fiter = file_handler.make_bag_file_iterator()\n",
    "#     data = []\n",
    "    \n",
    "#     if isinstance(file_handler, EssayFiles):\n",
    "#         AssignmentObj = EssayAssignment\n",
    "#         ComboObj = TermUnitStore\n",
    "#     elif isinstance(file_handler, JournalFiles):\n",
    "#         AssignmentObj = JournalAssignment(**d)\n",
    "#         ComboObj = TermWeekStore\n",
    "\n",
    "#     try:\n",
    "#         while True:\n",
    "#             with open(next(fiter), 'r') as f:\n",
    "#                 d = json.load(f)\n",
    "#                 o = AssignmentObj(**d)\n",
    "#                 data.append(o)\n",
    "\n",
    "#     except StopIteration:\n",
    "#         print(\"Loaded {} files\".format(len(data)))\n",
    "\n",
    "#     terms = list(set([e.term for e in data]))\n",
    "    \n",
    "#     try:\n",
    "#         divs = list(set([e.unit_number for e in data]))\n",
    "#     except NameError:\n",
    "#         divs = list(set([e.week_num for e in data]))\n",
    "\n",
    "#     stores = []\n",
    "#     for t in terms:\n",
    "#         for w in divs:\n",
    "#             stores.append(ComboObj(t, w, data))\n",
    "\n",
    "# #     len(week_stores)\n",
    "    \n",
    "#     return stores, terms, divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores, terms, units = load_stored_bags(file_handler)\n",
    "\n",
    "word_counts = pd.DataFrame([{'unit' : s.unit, 'word_count': b} for s in stores for b in s.bag_word_counts])\n",
    "# word_counts.set_index('unit', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data=word_counts, y='word_count', x='unit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts[word_counts.unit == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.set_index('unit', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.kdeplot(word_counts[word_counts.unit == 2], color='r', label='unit 2')\n",
    "for i in range(1, 5):\n",
    "    sns.kdeplot(word_counts.loc[i].word_count, label='unit {}'.format(i))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons of student responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentRepo = StudentRepository(environment.CONFIG.course)\n",
    "studentRepo.download()\n",
    "\n",
    "\n",
    "if environment.CONFIG.is_test:\n",
    "    # testing: in memory db\n",
    "    dao = SqliteDAO()\n",
    "    print(\"Connected to testing db\")\n",
    "else:\n",
    "    db_filepath = \"{}/{}-Unit-{}-discussion-review.db\".format( environment.LOG_FOLDER, SEMESTER_NAME, environment.CONFIG.unit_number)\n",
    "    # real: file db\n",
    "    dao = SqliteDAO(db_filepath)\n",
    "    dao.initialize_db_file()\n",
    "    print(\"Connected to REAL db\")\n",
    "\n",
    "associationRepo = AssociationRepository(dao, environment.CONFIG.unit.discussion_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewRepo = ReviewRepository(environment.CONFIG.unit.review, environment.CONFIG.course)\n",
    "reviewRepo.data = get_newest_data(environment.CONFIG.unit.review)\n",
    "reviewRepo.set_question_columns(reviewRepo.data)\n",
    "reviewRepo._fix_forgot_answers()\n",
    "\n",
    "# add assessees\n",
    "reviewRepo.data['assessee_id'] = reviewRepo.data.apply(lambda x: associationRepo.get_assessee(environment.CONFIG.unit.review, x.student_id), axis=1)\n",
    "\n",
    "reviewRepo.data.dropna(subset=['assessee_id'], inplace=True)\n",
    "\n",
    "len(reviewRepo.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviewRepo.data.assessee_id = reviewRepo.data.assessee_id.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewRepo.data.assessee_id.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# def fix_forgot_answers(reviewRepo):\n",
    "#     def r(v):\n",
    "#         if v == 'They forgot to do this':\n",
    "#             return 'Forgot'\n",
    "#         return v\n",
    "\n",
    "#     for c in reviewRepo.multiple_choice_names:\n",
    "#         reviewRepo.data[c] = reviewRepo.data.apply(lambda x: r(x[c]), axis=1)\n",
    "\n",
    "# def rotate_x_labels(axis, degrees=45):\n",
    "#     for tick in axis.get_xticklabels():\n",
    "#         tick.set_rotation(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fix_forgot_answers(reviewRepo)\n",
    "d = reviewRepo.data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = nrows=round(len(reviewRepo.multiple_choice_names)/2)\n",
    "fig, axes = plt.subplots(ncols=2, nrows=rows, figsize=(12,20))\n",
    "\n",
    "row=0; col=0\n",
    "for c in reviewRepo.multiple_choice_names:\n",
    "    title = c.split(':')[1][:65]\n",
    "    g = sns.countplot(d[c], order=environment.LIKERT_PLOT_ORDER, palette='plasma', ax=axes[row, col])\n",
    "    g.set_xlabel('')\n",
    "    axes[row, col].set_title(title)\n",
    "    rotate_x_labels(axes[row, col])\n",
    "    if col == 1:\n",
    "        row += 1\n",
    "        col = 0\n",
    "    else:\n",
    "        col += 1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do reviewers and reviewees rate each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numd = d.copy(deep=True)\n",
    "\n",
    "\n",
    "for c in reviewRepo.multiple_choice_names:\n",
    "    numd[c] = numd.apply(lambda x: environment.LIKERT_NUM_MAP.get(x[c]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numd.set_index('student_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for i, row in numd.iterrows():\n",
    "    f.append( {\n",
    "        'assessor' : i,\n",
    "        'assessee' : row.assessee_id,\n",
    "        'total' : sum(row[reviewRepo.multiple_choice_names])\n",
    "    })\n",
    "f = pd.DataFrame(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = f.copy(deep=True)\n",
    "g.set_index('assessee', inplace=True)\n",
    "f.set_index('assessor', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[]\n",
    "for sid in f.index:\n",
    "    try:\n",
    "        # gave, recieved\n",
    "        gave = f.loc[sid].total.mean()\n",
    "        recd = g.loc[sid].total.mean()\n",
    "        b.append({'gave': gave, 'recd': recd, 'gap': gave - recd})\n",
    "    except KeyError:\n",
    "        pass\n",
    "b = pd.DataFrame(b)\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 : Gave and received the same\n",
    "\n",
    "\\> 0: Gave a better score than they received\n",
    "\n",
    "< 0: Received a better score than they gave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(b.gap.dropna(), rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b[b.gap >0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b[b.gap < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(b.gave, b.recd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='gave', y='recd', data=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(y='gave', x='recd', data=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback on course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_test_selector()\n",
    "make_unit_chooser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit.unit_end_survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TERM = 'S20'\n",
    "\n",
    "SURVEY_FOLDER = '/Users/adam/Box Sync/TEACHING/Phil 305 Business ethics/Surveys/{}'.format(TERM)\n",
    "\n",
    "def get_unit(filename):\n",
    "    s = filename.split('_')[0][-1 : ]\n",
    "    return int(s)\n",
    "\n",
    "fiter = makeDataFileIterator( SURVEY_FOLDER )\n",
    "report_frames = [ ]\n",
    "try:\n",
    "    while True:\n",
    "        f = next( fiter )\n",
    "        unit_num = get_unit(f)\n",
    "        print( \"loading: \", f )\n",
    "        frame = pd.read_csv( f )\n",
    "        frame['term'] = TERM\n",
    "        frame['unit'] = unit_num\n",
    "        # this makes it freak out for some reason\n",
    "        #         frame.set_index('student_id', inplace=True)\n",
    "        report_frames.append( frame )\n",
    "except StopIteration:\n",
    "    pass\n",
    "\n",
    "class_data = report_frames[0]\n",
    "len(class_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyRepo = ReviewRepository(unit.unit_end_survey, course)\n",
    "surveyRepo.data = class_data\n",
    "surveyRepo.set_question_columns(surveyRepo.data)\n",
    "fix_forgot_answers(surveyRepo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_ORDER = ['Less than 1 hour', '1-3 hours', '3-5 hours', '5-7 hours', 'More than 7 hours']\n",
    "\n",
    "rows = nrows=round(len(surveyRepo.multiple_choice_names)/2)\n",
    "fig, axes = plt.subplots(ncols=2, nrows=rows, figsize=(12,30))\n",
    "\n",
    "row=0; col=0\n",
    "for c in surveyRepo.multiple_choice_names:\n",
    "    title = c.split(':')[1][:65]\n",
    "    if c == surveyRepo.multiple_choice_names[0]:\n",
    "        order = TIME_ORDER\n",
    "    else:\n",
    "        order = [l for l in environment.LIKERT_PLOT_ORDER if l != 'Forgot']\n",
    "        \n",
    "    g = sns.countplot(surveyRepo.data[c], order=order, palette='plasma', ax=axes[row, col])\n",
    "    g.set_xlabel('')\n",
    "    axes[row, col].set_title(title)\n",
    "    rotate_x_labels(axes[row, col])\n",
    "    if col == 1:\n",
    "        row += 1\n",
    "        col = 0\n",
    "    else:\n",
    "        col += 1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def get_newest_data(activity):\n",
    "    # get data from newest file\n",
    "    fiter = makeDataFileIterator( activity.folder_path )\n",
    "    report_frames = [ ]\n",
    "    try:\n",
    "        while True:\n",
    "            f = next( fiter )\n",
    "            print( \"loading: \", f )\n",
    "            frame = pd.read_csv( f )\n",
    "            frame.submitted = pd.to_datetime( frame.submitted )\n",
    "            if 'student_id' not in frame.index:\n",
    "                frame.rename( { 'id': 'student_id' }, axis=1, inplace=True )\n",
    "            # this makes it freak out for some reason\n",
    "            #         frame.set_index('student_id', inplace=True)\n",
    "            report_frames.append( frame )\n",
    "    except StopIteration:\n",
    "        return sort_frames_by_age( report_frames )[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# TEST = False\n",
    "\n",
    "# environment.CONFIG.set_unit_number(1)\n",
    "\n",
    "# if TEST:\n",
    "#     environment.CONFIG.set_test()\n",
    "# # environment.CONFIG.set_live()\n",
    "\n",
    "# COURSE_ID = environment.CONFIG.course_ids[0]\n",
    "# print(\"Working on course: \", COURSE_ID)\n",
    "\n",
    "\n",
    "# UNIT_NUMBER = 1\n",
    "\n",
    "# _initialize based on selection\n",
    "# todo eventually should be integrated into config\n",
    "# course = canvas.get_course(COURSE_ID)\n",
    "# unit = Unit(course, environment.CONFIG.unit)\n",
    "# codeRepo = AccessCodeRepo(ACCESS_CODES_FP, environment.CONFIG.unit)\n",
    "\n",
    "\n",
    "\n",
    "# if TEST:\n",
    "#     # testing: in memory db\n",
    "#     dao = SqliteDAO()\n",
    "#     print(\"Connected to testing db\")\n",
    "# else:\n",
    "#     db_filepath = \"{}/{}-Unit-{}-review-assigns.db\".format( environment.LOG_FOLDER, SEMESTER_NAME, environment.CONFIG.unit)\n",
    "#     # real: file db\n",
    "#     dao = SqliteDAO(db_filepath)\n",
    "#     dao.initialize_db_file()\n",
    "#     print(\"Connected to REAL db\")\n",
    "\n",
    "# associationRepo = AssociationRepository(dao, unit.review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canvashacks",
   "language": "python",
   "name": "canvashacks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48.2333px",
    "width": "251.1px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
