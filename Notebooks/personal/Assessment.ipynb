{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "%cd ~/Dropbox/CanvasHacks\n",
    "\n",
    "#Plotting \n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf')\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_palette(sns.color_palette('plasma'))\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf')\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import ColumnDataSource, Band, Span\n",
    "# output to static HTML \n",
    "output_notebook()\n",
    "\n",
    "#numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "pd.set_option('precision', 2)\n",
    "pd.options.plotting.matplotlib.register_converters = True\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "from CanvasHacks import environment\n",
    "from CanvasHacks.Api.RequestTools import *\n",
    "from CanvasHacks.Api.UrlTools import *\n",
    "from CanvasHacks.Configuration import InteractiveConfiguration\n",
    "# import CanvasHacks.GradingTools as GT\n",
    "# import CanvasHacks.DownloadProcessingTools as PT\n",
    "\n",
    "# File system\n",
    "from CanvasHacks.TimeTools import getDateForMakingFileName\n",
    "from CanvasHacks.Files.FileTools import  create_folder, makeDataFileIterator\n",
    "from CanvasHacks.Files.JournalsFileTools import get_journal_folders, make_folder_list, calculate_journal_counts\n",
    "from CanvasHacks.Files.QuizReportFileTools import sort_frames_by_age, get_newest_data\n",
    "\n",
    "# from CanvasHacks.JournalsFileTools import journal_folder_name, create_folder\n",
    "# from CanvasHacks.FileTools import getDateForMakingFileName\n",
    "\n",
    "# Canvas api\n",
    "from canvasapi import Canvas\n",
    "from canvasapi.quiz import QuizReport, Quiz\n",
    "from canvasapi.requester import Requester\n",
    "from canvasapi.conversation import Conversation\n",
    "\n",
    "# Initialize a Canvas api objects\n",
    "canvas = Canvas(environment.CONFIG.canvas_url_base, environment.CONFIG.canvas_token)\n",
    "requester = Requester(environment.CONFIG.canvas_url_base, environment.CONFIG.canvas_token)\n",
    "\n",
    "# Configuration\n",
    "from CanvasHacks.Definitions.skaa import Review, InitialWork, MetaReview\n",
    "from CanvasHacks.Definitions.unit import Unit #Assignment\n",
    "\n",
    "# Exceptions\n",
    "# from CanvasHacks.Errors.review_associations import AlreadyAssigned, SubmissionIncomplete\n",
    "\n",
    "# Models\n",
    "from CanvasHacks.Models.student import Student\n",
    "from CanvasHacks.Models.student import student_from_canvas_user, ensure_student\n",
    "\n",
    "# Repos\n",
    "from CanvasHacks.Repositories.DataManagement import DataStore\n",
    "from CanvasHacks.Repositories.quizzes import QuizRepository, ReviewRepository\n",
    "from CanvasHacks.Repositories.codes import AccessCodeRepo\n",
    "from CanvasHacks.Repositories.reviewer_associations import assign_reviewers, AssociationRepository\n",
    "from CanvasHacks.Repositories.students import StudentRepository\n",
    "from CanvasHacks.Repositories.factories import WorkRepositoryLoaderFactory\n",
    "\n",
    "\n",
    "# Storage\n",
    "from CanvasHacks.DAOs.sqlite_dao import SqliteDAO\n",
    "\n",
    "# Widgets\n",
    "from CanvasHacks.Widgets.ConsolidatedTextOutput import make_assignment_header, make_consolidated_text_fields\n",
    "from CanvasHacks.Widgets.InputFields import make_course_ids_input, make_canvas_token_input, make_canvas_url_input, make_general_reset_button\n",
    "from CanvasHacks.Widgets.AssignmentSelection import make_assignment_chooser, view_selected_assignments, view_ungraded_assignments\n",
    "from CanvasHacks.Widgets.LiveSelection import make_test_selector\n",
    "from CanvasHacks.Widgets.AssignmentSelection import make_unit_chooser\n",
    "\n",
    "\n",
    "from CanvasHacks.Repositories.status import FeedbackStatusRepository, InvitationStatusRepository\n",
    "from CanvasHacks.Repositories.students import StudentRepository\n",
    "from CanvasHacks.Models.status_record import ComplexStatusRecord, FeedbackReceivedRecord, InvitationReceivedRecord,\\\n",
    "    StatusRecord\n",
    "\n",
    "from CanvasHacks.SkaaSteps.ISkaaSteps import IStep\n",
    "\n",
    "\n",
    "# Plotting\n",
    "from CanvasHacks.Text.VisualizationTools import rotate_x_labels\n",
    "# from CanvasHacks.Repositories.quizzes import fix_forgot_answers\n",
    "\n",
    "import inspect\n",
    "def look_inside(obj):\n",
    "    print(inspect.getmembers(obj, lambda a:not(inspect.isroutine(a))))\n",
    "    \n",
    "    \n",
    "SEMESTER_NAME = 'S20'\n",
    "LOC = '{}/Box Sync/TEACHING/Phil 305 Business ethics/Phil305 S20'.format(environment.ROOT)# placeholder for where the access codes are stored\n",
    "ACCESS_CODES_FP = \"{}/{}-assignment-access-codes.xlsx\".format(LOC, SEMESTER_NAME)\n",
    "    \n",
    "    \n",
    "# LIKERT_PLOT_ORDER = ['Forgot', 'Strongly disagree', 'Disagree', 'Agree', 'Strongly agree']\n",
    "# LIKERT_NUM_MAP = {'Forgot' : 0, 'Strongly disagree': 1, 'Disagree': 2, 'Agree': 3, 'Strongly agree': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "CLASS_IDS  = {\n",
    "    'F19': [62657, 67473, 62660],\n",
    "    'F18': [41179, 41180, 41181],\n",
    "    'S19': [67531],\n",
    "    'S20': [77522],\n",
    "    'F20' : [79991] \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of semester data archiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from CanvasHacks.Assessment.api import get_all_essay_assigns_for_class, store_course_essays, store_course_reviews\n",
    "from CanvasHacks.Api.RequestTools import get_all_course_assignments\n",
    "from CanvasHacks.Definitions.skaa import InitialWork\n",
    "from CanvasHacks.Assessment.processing import process_essay_entries\n",
    "from CanvasHacks.Assessment.files import EssayFiles\n",
    "\n",
    "from CanvasHacks.Assessment.api import get_all_journal_assigns_for_class, store_course_journals\n",
    "from CanvasHacks.Assessment.processing import process_journal_entries\n",
    "from CanvasHacks.Assessment.files import JournalFiles #make_content_filepath, make_bag_filepath, make_week_iterator, \n",
    "\n",
    "#     'F20' : [79991] \n",
    "# SEMESTER_NAME = 'F20'\n",
    " \n",
    "SEMESTER_NAME = 'S21'\n",
    "# courses_to_get = [  79991]\n",
    "courses_to_get = environment.CONFIG.course_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Download and store\n",
    "for cid in courses_to_get:\n",
    "    store_course_essays(cid, SEMESTER_NAME, start_unit=1)\n",
    "\n",
    "# Process into bags\n",
    "filename_handler = EssayFiles()\n",
    "\n",
    "fiter = filename_handler.make_content_file_iterator()\n",
    "existing = filename_handler.bag_files\n",
    "\n",
    "while True:\n",
    "    with open(next(fiter), 'r') as f:\n",
    "        print(\"Processing \", f.name.split('/')[-1:])\n",
    "        entries = json.load(f)\n",
    "        process_essay_entries(entries, existing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Download and store\n",
    "for cid in courses_to_get:\n",
    "    try:\n",
    "        store_course_journals(cid, SEMESTER_NAME, start_week=1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Process into bags\n",
    "filename_maker = JournalFiles()\n",
    "\n",
    "fiter = filename_maker.make_content_file_iterator()\n",
    "existing = filename_maker.bag_files\n",
    "\n",
    "while True:\n",
    "    with open(next(fiter), 'r') as f:\n",
    "        print(\"Processing \", f.name.split('/')[-1:])\n",
    "        entries = json.load(f)\n",
    "        process_journal_entries(entries, existing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_course_reviews(courses_to_get[0], SEMESTER_NAME, start_unit=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_unit_chooser(num_units=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.CONFIG.unit.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unit_numbers = [i for i in range(1,9)]\n",
    "unit_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# course=environment.CONFIG.course, \n",
    "\n",
    "\n",
    "course=environment.CONFIG.course \n",
    "\n",
    "\n",
    "\n",
    "unit_numbers = [i for i in range(1,9)]\n",
    "\n",
    "for unit_number in unit_numbers:\n",
    "    environment.CONFIG.set_unit_number(unit_number)\n",
    "    environment.CONFIG.initialize_canvas_objs()\n",
    "    environment.CONFIG.unit = Unit(environment.CONFIG.course, unit_number)\n",
    "    \n",
    "    if len(environment.CONFIG.unit.components) == 0:\n",
    "        print('k')\n",
    "        continue\n",
    "    \n",
    "    print('j')\n",
    "\n",
    "    \n",
    "# activity=environment.CONFIG.unit.review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_type(activity):\n",
    "    if isinstance(activity, MetaReview):\n",
    "        return 'metareview'\n",
    "    if isinstance(activity, Review):\n",
    "        return 'review'\n",
    "activity_type(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "              \n",
    "                                              \n",
    "reviewRepo = WorkRepositoryLoaderFactory.make(course=course, \n",
    "                                              activity=activity, \n",
    "                                              save=False, \n",
    "                                              download=False,\n",
    "                                             rest_timeout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [ 'n correct', 'n incorrect', 'score_x',  'score_y', 'workflow_state']\n",
    "d = reviewRepo.data.copy(deep=True)\n",
    "d['unit'] = environment.CONFIG.unit.unit_number\n",
    "d['activity_type'] = activity_type(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Download and store\n",
    "for cid in courses_to_get:\n",
    "    try:\n",
    "        store_course_reviews(cid, SEMESTER_NAME, start_week=1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Process into bags\n",
    "filename_maker = ReviewFiles()\n",
    "\n",
    "fiter = filename_maker.make_content_file_iterator()\n",
    "existing = filename_maker.bag_files\n",
    "\n",
    "while True:\n",
    "    with open(next(fiter), 'r') as f:\n",
    "        print(\"Processing \", f.name.split('/')[-1:])\n",
    "        entries = json.load(f)\n",
    "        process_review_entries(entries, existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring student progress in the class\n",
    "## Determine completions per day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "make_unit_chooser(num_units=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = IStep(unit=environment.CONFIG.unit)\n",
    "s._initialize_db()\n",
    "\n",
    "review = environment.CONFIG.unit.review\n",
    "essay = environment.CONFIG.unit.initial_work\n",
    "inv = InvitationStatusRepository( s.dao, review )\n",
    "fr = FeedbackStatusRepository( s.dao, essay )\n",
    "\n",
    "invites = inv.get_daily_counts()\n",
    "fdsnt = fr.get_daily_counts()\n",
    "# invites\n",
    "\n",
    "nm = invites.activity_name[0]\n",
    "fdsnt.set_index(['activity_id', 'activity_name'], inplace=True)\n",
    "invites.set_index(['activity_id', 'activity_name'], inplace=True)\n",
    "counts = pd.merge(invites, fdsnt, left_on='sent_at', right_on='sent_at')\n",
    "counts['activity_name'] = nm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_assignment_chooser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All submissions from all unit assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CanvasHacks.Repositories.submissions import AssignmentSubmissionRepository\n",
    "unit_nums = [u for u in range(1, 7)]\n",
    "\n",
    "counts = {}\n",
    "for u in unit_nums:\n",
    "    environment.CONFIG.set_unit(u)\n",
    "    unit = environment.CONFIG.unit\n",
    "    ucs = []\n",
    "    for c in unit.components:\n",
    "        assignment = environment.CONFIG.course.get_assignment( c.id )\n",
    "        ar = AssignmentSubmissionRepository(assignment)\n",
    "        ucs.append(ar.get_daily_counts(activity_name=c.activity_name))\n",
    "    ucs = pd.concat(ucs)\n",
    "    counts[u] = ucs\n",
    "# # counts\n",
    "#     for assignment_id, assignment_name in environment.CONFIG.assignments:\n",
    "#     assignment = environment.CONFIG.course.get_assignment( assignment_id )\n",
    "#     ar = AssignmentSubmissionRepository(assignment)\n",
    "#     counts.append(ar.get_daily_counts(activity_name=assignment_name))\n",
    "# counts = pd.concat(counts)\n",
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=6, figsize=(10,10))\n",
    "# for u in unit_nums:\n",
    "\n",
    "#     c = counts[u].reset_index()\n",
    "\n",
    "#     g = sns.relplot(x=\"submitted_at\", y=\"num_submissions\",  data=c, hue='activity_name', ax=axes[u-1])\n",
    "#     # g.fig.set_title('Unit {}')\n",
    "# fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = []\n",
    "for unum, frame in counts.items():\n",
    "    frame['unit'] = unum\n",
    "    frame['day'] = frame.index.day_name()\n",
    "    submission_data.append(frame)\n",
    "submission_data = pd.concat(submission_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_ORDER = ['Monday','Tuesday','Wednesday', 'Thursday', 'Friday', 'Saturday',  'Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.catplot(x=\"day\", y=\"num_submissions\", \n",
    "            order=DAY_ORDER, \n",
    "            hue=\"unit\",\n",
    "            kind='bar',\n",
    "            data=submission_data, height=4, aspect=2, legend_out=False);\n",
    "rotate_x_labels(p.ax)\n",
    "p.ax.legend(loc='upper center', title='Unit')\n",
    "p.fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data.groupby('activity_name').num_submissions.sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_completions_for_unit(submission_data, unit_number):\n",
    "    d = submission_data[submission_data.unit == unit_number]\n",
    "    d = pd.DataFrame(d.groupby([ 'activity_name']).sum()).reset_index()\n",
    "    source = ColumnDataSource(d)\n",
    "    \n",
    "    p = figure(\n",
    "        plot_width=1000,\n",
    "        plot_height=400,\n",
    "#         x_range=group,\n",
    "        title=\"Cumulative submission counts\")#,\n",
    "#         x_axis_type='datetime')  #,\n",
    "    #            tooltips=TOOLTIPS)\n",
    "\n",
    "    p.vbar(\n",
    "            x='activity_name',\n",
    "            top='num_submissions',\n",
    "            color=\"green\",\n",
    "            width=0.4,\n",
    "    #     source=group,\n",
    "    #     fill_color=index_cmap,\n",
    "            source=source,\n",
    "            alpha=0.8)#,\n",
    "    #         legend_label=f'Daily new {title_word}')\n",
    "    show(p)\n",
    "    \n",
    "    \n",
    "plot_cumulative_completions_for_unit(submission_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.catplot(x=\"activity_name\", y=\"num_submissions\", \n",
    "            hue=\"unit\",\n",
    "            kind='bar',\n",
    "            data=gd.reset_index(), height=4, aspect=2, legend_out=False);\n",
    "rotate_x_labels(p.ax)\n",
    "p.ax.legend(loc='upper center', title='Unit')\n",
    "p.fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sns.set_palette(sns.color_palette('plasma'))\n",
    "from bokeh.palettes import Spectral5\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "counts_comb.unit = counts_comb.unit.astype(str)\n",
    "# group = counts_comb.groupby(by=[ 'unit', 'day'])       \n",
    "# group = df.groupby(by=['cyl', 'mfr'])\n",
    "\n",
    "# index_cmap = factor_cmap('day_unit', palette=Spectral5, factors=sorted(counts_comb.unit.unique()), end=1)\n",
    "\n",
    "# p = figure(plot_width=800, plot_height=300, title=\"Mean MPG by # Cylinders and Manufacturer\",\n",
    "#            x_range=group, toolbar_location=None, tooltips=[(\"MPG\", \"@mpg_mean\"), (\"Cyl, Mfr\", \"@cyl_mfr\")])\n",
    "\n",
    "\n",
    "group = pd.DataFrame(counts_comb.groupby(['unit', 'day']).num_submissions.sum())\n",
    "\n",
    "# group = counts_comb.groupby('unit')\n",
    "\n",
    "\n",
    "d=counts_comb\n",
    "source = ColumnDataSource(group)\n",
    "p = figure(\n",
    "        plot_width=1000,\n",
    "        plot_height=400,\n",
    "    x_range=group,\n",
    "        title=\"Daily submission counts\")#,\n",
    "#         x_axis_type='datetime')  #,\n",
    "    #            tooltips=TOOLTIPS)\n",
    "\n",
    "\n",
    "#     source2 = ColumnDataSource(frame.rolling(window='7D').mean().reset_index())\n",
    "\n",
    "    # add a circle renderer with a size, color, and alpha\n",
    "    # p.circle(x='date', y='new_confirmed_cases', size=10, color=\"navy\", source=source, alpha=0.5)\n",
    "p.vbar(\n",
    "        x='day_unit',\n",
    "        top='num_submissions',\n",
    "#         color=\"green\",\n",
    "        width=0.4,\n",
    "#     source=group,\n",
    "#     fill_color=index_cmap,\n",
    "        source=source,\n",
    "        alpha=0.8)#,\n",
    "#         legend_label=f'Daily new {title_word}')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative completions (run logs)\n",
    "\n",
    "\n",
    "Notes\n",
    "\n",
    "\n",
    "    Maybe this should be done off of the submissions (think I started that elsewhere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Started working on this elsewhere. Similar idea to the above, but\n",
    "# this uses the logs from the skaa runner\n",
    "\n",
    "bad_stem = 'Unnamed:'\n",
    "\n",
    "data = pd.read_excel(environment.RUN_DATA_LOG_PATH)\n",
    "unit_nums = list(set(data.unit_number.tolist()))\n",
    "\n",
    "to_drop = [ c for c in data.columns if c[: len(bad_stem) ] == bad_stem]\n",
    "# These are just the inverse of the essay and posts\n",
    "to_drop.extend(['no_essay', 'no_posts'])\n",
    "\n",
    "data.drop(to_drop, axis=1, inplace=True)\n",
    "# d.set_index(['ran_at'], inplace=True)\n",
    "# d.set_index('unit_number', inplace=True)\n",
    "# d.set_index(['unit_number', 'ran_at'], inplace=True)\n",
    "\n",
    "\n",
    "o = []\n",
    "for u in unit_nums:\n",
    "    a = data[data.unit_number == u].sort_values('ran_at')\n",
    "    a.set_index(['unit_number', 'ran_at'], inplace=True)\n",
    "    anew = a - a.shift(1)\n",
    "    o.append(anew)\n",
    "\n",
    "new = pd.concat(o).dropna()\n",
    "# new\n",
    "\n",
    "g = sns.barplot(x=\"ran_at\", y=\"essay\",\n",
    "            hue=\"unit_number\", data=new.reset_index());\n",
    "g.ax.set_title(\"Cummulative essay submissions\")\n",
    "g.fig.autofmt_xdate()\n",
    "# g.fig.set_size((5,5))\n",
    "\n",
    "data.essay.plot(kind='bar')\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(8,4))\n",
    "new.essay.plot(kind='bar', ax=axes)\n",
    "fig.autofmt_xdate(); fig.tight_layout()\n",
    "# fig.set_tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_comb\n",
    "g = sns.relplot(x=\"submitted_at\", y=\"num_submissions\",  data=submission_data.reset_index(), hue='unit',\n",
    "                height=4, aspect=2)\n",
    "rotate_x_labels(g.ax)\n",
    "g.fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "    TOOLTIPS = [\n",
    "        (\"new_confirmed_cases\", \"$index\"),\n",
    "        (\"(x,y)\", \"($x, $y)\"),\n",
    "        #     (\"desc\", \"@desc\"),\n",
    "    ]\n",
    "\n",
    "    p = figure(\n",
    "        plot_width=1000,\n",
    "        plot_height=400,\n",
    "        title=f\"Daily new {title_word} {place}\",\n",
    "        x_axis_type='datetime')  #,\n",
    "    #            tooltips=TOOLTIPS)\n",
    "\n",
    "    source = ColumnDataSource(frame.reset_index())\n",
    "    source2 = ColumnDataSource(frame.rolling(window='7D').mean().reset_index())\n",
    "\n",
    "    # add a circle renderer with a size, color, and alpha\n",
    "    # p.circle(x='date', y='new_confirmed_cases', size=10, color=\"navy\", source=source, alpha=0.5)\n",
    "    p.vbar(\n",
    "        x='date',\n",
    "        top=field_name,\n",
    "        color=\"green\",\n",
    "        width=0.4,\n",
    "        source=source,\n",
    "        alpha=0.8,\n",
    "        legend_label=f'Daily new {title_word}')\n",
    "    p.line(\n",
    "        x='date',\n",
    "        y=field_name,\n",
    "        line_width=5,\n",
    "        color=\"navy\",\n",
    "        source=source2,\n",
    "        alpha=0.3,\n",
    "        legend_label='7-day rolling avg')\n",
    "\n",
    "    # df['lower'] = df.new_confirmed_cases.mean() - df.new_confirmed_cases.std()\n",
    "    # df['upper'] = df.new_confirmed_cases.mean() + df.new_confirmed_cases.std()\n",
    "    # band = Band(base='x', lower='lower', upper='upper', source=source, level='underlay',\n",
    "    #             fill_alpha=1.0, line_width=1, line_color='black')\n",
    "    # p.add_layout(band)\n",
    "\n",
    "    # show the results\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_test_selector()\n",
    "make_unit_chooser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.CONFIG.course_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student responses on reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "make_test_selector()\n",
    "make_unit_chooser(num_units=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentRepo = StudentRepository(environment.CONFIG.course)\n",
    "studentRepo.download()\n",
    "    \n",
    "dh = IStep(unit=environment.CONFIG.unit)\n",
    "dh._initialize_db()\n",
    "dao = dh.dao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_review_responses(reviewRepo):\n",
    "    \"\"\"\n",
    "    Plots answers to the review questions with bar graphs\n",
    "    arranged in two columns. \n",
    "    \n",
    "    This fits on the pdf output pretty well\n",
    "    \"\"\"\n",
    "    \n",
    "    rows = nrows=round(len(reviewRepo.multiple_choice_names)/2) #+1\n",
    "    fig, axes = plt.subplots(ncols=2, nrows=rows, figsize=(12,20))\n",
    "\n",
    "    row=0; col=0\n",
    "    for c in reviewRepo.multiple_choice_names:\n",
    "        title = c.split(':')[1][:65]\n",
    "        g = sns.countplot(reviewRepo.data[c], \n",
    "                          order=environment.LIKERT_PLOT_ORDER, \n",
    "                          palette='plasma', \n",
    "                          ax=axes[row, col])\n",
    "        g.set_xlabel('')\n",
    "        axes[row, col].set_title(title)\n",
    "        rotate_x_labels(axes[row, col])\n",
    "        if col == 1:\n",
    "            row += 1\n",
    "            col = 0\n",
    "        else:\n",
    "            col += 1\n",
    "\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summaries of reviewer responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discussion_assocRepo = AssociationRepository(dh.dao, environment.CONFIG.unit.discussion_review)\n",
    "\n",
    "\n",
    "discussionReviewRepo = WorkRepositoryLoaderFactory.make(course=environment.CONFIG.course, \n",
    "                                              activity=environment.CONFIG.unit.discussion_review, \n",
    "                                              save=False, \n",
    "                                             rest_timeout=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_review_responses(discussionReviewRepo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essay reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_assocRepo = AssociationRepository(essay_dao, environment.CONFIG.unit.initial_work)\n",
    "\n",
    "essayReviewRepo = WorkRepositoryLoaderFactory.make(course=environment.CONFIG.course, \n",
    "                                              activity=environment.CONFIG.unit.review, \n",
    "                                              save=False, \n",
    "                                             rest_timeout=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summaries of reviewer responses\n",
    "\n",
    "ToDo\n",
    "    \n",
    "    Look at each student across all reviews and figure out how much variation there is in the grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviewRepo.data.assessee_id = reviewRepo.data.assessee_id.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_review_responses(essayReviewRepo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do reviewers and reviewees rate each other\n",
    "\n",
    "(Not sure that this is working because of the triad review structure)\n",
    "\n",
    "NB, Only available in units with metareview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add assessee id to the reviewRepo dataframe\n",
    "essayReviewRepo.add_review_assignments()\n",
    "\n",
    "\n",
    "numd = essayReviewRepo.data.copy(deep=True)\n",
    "\n",
    "\n",
    "for c in essayReviewRepo.multiple_choice_names:\n",
    "    numd[c] = numd.apply(lambda x: environment.LIKERT_NUM_MAP.get(x[c]), axis=1)\n",
    "\n",
    "\n",
    "try:\n",
    "    numd.set_index('student_id', inplace=True)\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for i, row in numd.iterrows():\n",
    "    f.append( {\n",
    "        'assessor' : i,\n",
    "        'assessee' : row.assessee_id,\n",
    "        'total' : sum(row[essayReviewRepo.multiple_choice_names])\n",
    "    })\n",
    "f = pd.DataFrame(f)\n",
    "\n",
    "g = f.copy(deep=True)\n",
    "g.set_index('assessee', inplace=True)\n",
    "f.set_index('assessor', inplace=True)\n",
    "\n",
    "b=[]\n",
    "for sid in f.index:\n",
    "    try:\n",
    "        # gave, recieved\n",
    "        gave = f.loc[sid].total.mean()\n",
    "        recd = g.loc[sid].total.mean()\n",
    "        b.append({'gave': gave, 'recd': recd, 'gap': gave - recd})\n",
    "    except KeyError:\n",
    "        pass\n",
    "b = pd.DataFrame(b)\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 : Gave and received the same\n",
    "\n",
    "\\> 0: Gave a better score than they received\n",
    "\n",
    "< 0: Received a better score than they gave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.gap.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = sns.distplot(b.gap.dropna(), rug=True)\n",
    "g.axes.set_xlim((b.gap.min(), b.gap.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.violinplot(b.gap.dropna())\n",
    "g.axes.set_xlim((b.gap.min(), b.gap.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b[b.gap >0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b[b.gap < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(b.gave, b.recd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='gave', y='recd', data=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(y='gave', x='recd', data=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from CanvasHacks.Assessment.api import get_all_essay_assigns_for_class, store_course_essays\n",
    "from CanvasHacks.Api.RequestTools import get_all_course_assignments\n",
    "from CanvasHacks.Definitions.skaa import InitialWork\n",
    "from CanvasHacks.Assessment.processing import process_essay_entries\n",
    "from CanvasHacks.Assessment.files import EssayFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire, clean, and store text\n",
    "\n",
    "### Acquire new assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "for cid in environment.CONFIG.course_ids:\n",
    "    store_course_essays(cid, 'S20', start_unit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and store wordbags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "filename_handler = EssayFiles()\n",
    "\n",
    "fiter = filename_handler.make_content_file_iterator()\n",
    "existing = filename_handler.bag_files\n",
    "\n",
    "while True:\n",
    "    with open(next(fiter), 'r') as f:\n",
    "        print(\"Processing \", f.name.split('/')[-1:])\n",
    "        entries = json.load(f)\n",
    "        process_essay_entries(entries, existing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load bags\n",
    "\n",
    "ToDo\n",
    "\n",
    "    Unit 1 from S20 was a quiz assignment so the data needs to be created differently "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CanvasHacks.Assessment.store import load_stored_bags, EssayAssignment, JournalAssignment, TermUnitStore, TermWeekStore, TokenFiltrationMixin\n",
    "filename_handler = EssayFiles()\n",
    "\n",
    "fiter = filename_handler.make_bag_file_iterator()\n",
    "data = []\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        with open(next(fiter), 'r') as f:\n",
    "#             print(f.name)\n",
    "            o = json.load(f)\n",
    "            data.append(o)\n",
    "\n",
    "except StopIteration:\n",
    "    print(\"Loaded {} files\".format(len(data)))\n",
    "\n",
    "\n",
    "stores, terms, units = load_stored_bags(filename_handler)\n",
    "\n",
    "word_counts = pd.DataFrame([{'term': s.term, 'unit' : s.unit, 'word_count': b} for s in stores for b in s.bag_word_counts])\n",
    "# word_counts.set_index('unit', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essay word counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All semesters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your question is 'how do students respond to word counts?' the answer is, they write more than before and exactly the limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(7, 4), nrows=2)\n",
    "sns.boxplot(data=word_counts, y='word_count', x='unit', ax=axes[0])\n",
    "sns.violinplot(data=word_counts, y='word_count', x='unit', ax=axes[1])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unit = 8\n",
    "d = word_counts.set_index('unit')\n",
    "sns.set_palette('plasma')\n",
    "# sns.kdeplot(word_counts[word_counts.unit == 2], color='r', label='unit 2')\n",
    "for i in range(1, max_unit +1):\n",
    "    try:\n",
    "        sns.kdeplot(d.loc[i].word_count, label='unit {}'.format(i))\n",
    "    except: \n",
    "        pass\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unit 6 for S21 vs other semesters (NB, refers to different essay prompt in S20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s21 = word_counts[ word_counts.term == 'S21'] # and word_counts.unit == 6]\n",
    "# unit6 = word_counts[ word_counts['term'] == 'S21'] # and word_counts.unit == 6]\n",
    "s21unit6 = s21[s21.unit == 6]\n",
    "# s21unit6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit6 = word_counts[word_counts.unit == 6] #.set_index('term')\n",
    "# unit6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(7, 6), nrows=2)\n",
    "plt.title('Unit 6 word counts')\n",
    "sns.boxplot(data=unit6, y='word_count', x='term', ax=axes[0])\n",
    "sns.violinplot(data=unit6, y='word_count', x='term', ax=axes[1])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit6_stats = unit6.groupby('term')['word_count']\n",
    "unit6_stats = pd.DataFrame(unit6_stats.describe())\n",
    "unit6_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pct change\n",
    "pct_diff = []\n",
    "for idx, row in unit6_stats.iterrows(): #.reset_index()\n",
    "    if idx != 'S21':\n",
    "        pct_of_mean = row.mean() / unit6_stats.loc['S21'].mean()\n",
    "        pct_of_median = row.median() / unit6_stats.loc['S21'].median()\n",
    "        d = {\n",
    "            'term' : idx,\n",
    "             'pct_increase_in_mean' : 1 - pct_of_mean,\n",
    "            'pct_increase_in_median' : 1 - pct_of_median\n",
    "        }\n",
    "        pct_diff.append(d)\n",
    "pct_diff = pd.DataFrame(pct_diff).set_index('term')\n",
    "pct_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_diff.plot(kind='bar')\n",
    "plt.title(\"Percent increase in S21 over previous terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit-end surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_test_selector()\n",
    "make_unit_chooser()\n",
    "\n",
    "\n",
    "TERM = 'S20'\n",
    "\n",
    "SURVEY_FOLDER = '/Users/adam/Box Sync/TEACHING/Phil 305 Business ethics/Surveys/{}'.format(TERM)\n",
    "\n",
    "def get_unit(filename):\n",
    "    s = filename.split('_')[0][-1 : ]\n",
    "    return int(s)\n",
    "\n",
    "fiter = makeDataFileIterator( SURVEY_FOLDER )\n",
    "report_frames = [ ]\n",
    "try:\n",
    "    while True:\n",
    "        f = next( fiter )\n",
    "        unit_num = get_unit(f)\n",
    "        print( \"loading: \", f )\n",
    "        frame = pd.read_csv( f )\n",
    "        frame['term'] = TERM\n",
    "        frame['unit'] = unit_num\n",
    "        # this makes it freak out for some reason\n",
    "        #         frame.set_index('student_id', inplace=True)\n",
    "        report_frames.append( frame )\n",
    "except StopIteration:\n",
    "    pass\n",
    "\n",
    "class_data = report_frames[0]\n",
    "# len(class_data)\n",
    "# class_data\n",
    "\n",
    "surveyRepo = ReviewRepository(unit.unit_end_survey, course)\n",
    "surveyRepo.data = class_data\n",
    "surveyRepo.set_question_columns(surveyRepo.data)\n",
    "fix_forgot_answers(surveyRepo)\n",
    "\n",
    "TIME_ORDER = ['Less than 1 hour', '1-3 hours', '3-5 hours', '5-7 hours', 'More than 7 hours']\n",
    "\n",
    "rows = nrows=round(len(surveyRepo.multiple_choice_names)/2)\n",
    "fig, axes = plt.subplots(ncols=2, nrows=rows, figsize=(12,30))\n",
    "\n",
    "row=0; col=0\n",
    "for c in surveyRepo.multiple_choice_names:\n",
    "    title = c.split(':')[1][:65]\n",
    "    if c == surveyRepo.multiple_choice_names[0]:\n",
    "        order = TIME_ORDER\n",
    "    else:\n",
    "        order = [l for l in environment.LIKERT_PLOT_ORDER if l != 'Forgot']\n",
    "        \n",
    "    g = sns.countplot(surveyRepo.data[c], order=order, palette='plasma', ax=axes[row, col])\n",
    "    g.set_xlabel('')\n",
    "    axes[row, col].set_title(title)\n",
    "    rotate_x_labels(axes[row, col])\n",
    "    if col == 1:\n",
    "        row += 1\n",
    "        col = 0\n",
    "    else:\n",
    "        col += 1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def get_newest_data(activity):\n",
    "    # get data from newest file\n",
    "    fiter = makeDataFileIterator( activity.folder_path )\n",
    "    report_frames = [ ]\n",
    "    try:\n",
    "        while True:\n",
    "            f = next( fiter )\n",
    "            print( \"loading: \", f )\n",
    "            frame = pd.read_csv( f )\n",
    "            frame.submitted = pd.to_datetime( frame.submitted )\n",
    "            if 'student_id' not in frame.index:\n",
    "                frame.rename( { 'id': 'student_id' }, axis=1, inplace=True )\n",
    "            # this makes it freak out for some reason\n",
    "            #         frame.set_index('student_id', inplace=True)\n",
    "            report_frames.append( frame )\n",
    "    except StopIteration:\n",
    "        return sort_frames_by_age( report_frames )[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# TEST = False\n",
    "\n",
    "# environment.CONFIG.set_unit_number(1)\n",
    "\n",
    "# if TEST:\n",
    "#     environment.CONFIG.set_test()\n",
    "# # environment.CONFIG.set_live()\n",
    "\n",
    "# COURSE_ID = environment.CONFIG.course_ids[0]\n",
    "# print(\"Working on course: \", COURSE_ID)\n",
    "\n",
    "\n",
    "# UNIT_NUMBER = 1\n",
    "\n",
    "# _initialize based on selection\n",
    "# todo eventually should be integrated into config\n",
    "# course = canvas.get_course(COURSE_ID)\n",
    "# unit = Unit(course, environment.CONFIG.unit)\n",
    "# codeRepo = AccessCodeRepo(ACCESS_CODES_FP, environment.CONFIG.unit)\n",
    "\n",
    "\n",
    "\n",
    "# if TEST:\n",
    "#     # testing: in memory db\n",
    "#     dao = SqliteDAO()\n",
    "#     print(\"Connected to testing db\")\n",
    "# else:\n",
    "#     db_filepath = \"{}/{}-Unit-{}-review-assigns.db\".format( environment.LOG_FOLDER, SEMESTER_NAME, environment.CONFIG.unit)\n",
    "#     # real: file db\n",
    "#     dao = SqliteDAO(db_filepath)\n",
    "#     dao.initialize_db_file()\n",
    "#     print(\"Connected to REAL db\")\n",
    "\n",
    "# associationRepo = AssociationRepository(dao, unit.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from CanvasHacks.DAOs.db_files import DBFilePathHandler\n",
    "# if environment.CONFIG.is_test:\n",
    "#     # testing: in memory db\n",
    "#     essay_dao = SqliteDAO()\n",
    "#     discussion_dao = SqliteDAO()\n",
    "#     print(\"Connected to testing db\")\n",
    "# else:\n",
    "#     discussion_dao = SqliteDAO(DBFilePathHandler.discussion_review(environment.CONFIG.unit_number))\n",
    "#     essay_dao = SqliteDAO(DBFilePathHandler.essay_review(environment.CONFIG.unit_number))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def load_stored_bags(file_handler):\n",
    "#     fiter = file_handler.make_bag_file_iterator()\n",
    "#     data = []\n",
    "    \n",
    "#     if isinstance(file_handler, EssayFiles):\n",
    "#         AssignmentObj = EssayAssignment\n",
    "#         ComboObj = TermUnitStore\n",
    "#     elif isinstance(file_handler, JournalFiles):\n",
    "#         AssignmentObj = JournalAssignment(**d)\n",
    "#         ComboObj = TermWeekStore\n",
    "\n",
    "#     try:\n",
    "#         while True:\n",
    "#             with open(next(fiter), 'r') as f:\n",
    "#                 d = json.load(f)\n",
    "#                 o = AssignmentObj(**d)\n",
    "#                 data.append(o)\n",
    "\n",
    "#     except StopIteration:\n",
    "#         print(\"Loaded {} files\".format(len(data)))\n",
    "\n",
    "#     terms = list(set([e.term for e in data]))\n",
    "    \n",
    "#     try:\n",
    "#         divs = list(set([e.unit_number for e in data]))\n",
    "#     except NameError:\n",
    "#         divs = list(set([e.week_num for e in data]))\n",
    "\n",
    "#     stores = []\n",
    "#     for t in terms:\n",
    "#         for w in divs:\n",
    "#             stores.append(ComboObj(t, w, data))\n",
    "\n",
    "# #     len(week_stores)\n",
    "    \n",
    "#     return stores, terms, divs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canv-env",
   "language": "python",
   "name": "canv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48.2333px",
    "width": "251.1px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
