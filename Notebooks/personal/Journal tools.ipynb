{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools for grading and analyzing student journals\n",
    "\n",
    "This is the non-public project notebook; for personal use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Dynamically sets location so do not have to manually toggle between dropbox and documents\n",
    "import os\n",
    "path = \"/\".join([a for a in os.path.abspath(\"\").split('/') if a not in ['Notebooks', 'personal']])\n",
    "%cd $path\n",
    "\n",
    "#Plotting \n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from CanvasHacks import environment\n",
    "\n",
    "from CanvasHacks.Api.RequestTools import get_all_course_assignments, get_assignments_needing_grading\n",
    "from CanvasHacks.Api.UploadGradeTools import make_upload_button\n",
    "\n",
    "from CanvasHacks.Configuration import InteractiveConfiguration\n",
    "from CanvasHacks.Widgets.InputFields import make_course_ids_input, make_canvas_token_input, make_canvas_url_input, make_general_reset_button\n",
    "# import CanvasHacks.GradingTools as GT\n",
    "# import CanvasHacks.DownloadProcessingTools as PT\n",
    "from CanvasHacks.Repositories.DataManagement import DataStore, DataStoreNew\n",
    "\n",
    "\n",
    "# This aren't used in the non-saving version\n",
    "# from CanvasHacks.Files.FileTools import makeDataFileIterator, create_folder\n",
    "# from CanvasHacks.JournalsFileTools import get_journal_folders, make_folder_list, calculate_journal_counts\n",
    "# from CanvasHacks.JournalsFileTools import journal_folder_name\n",
    "\n",
    "from CanvasHacks.Widgets.AssignmentSelection import make_assignment_chooser, view_selected_assignments, view_ungraded_assignments\n",
    "from CanvasHacks.Widgets.ConsolidatedTextOutput import make_assignment_header, make_consolidated_text_fields\n",
    "from CanvasHacks.Widgets.LiveSelection import make_test_selector\n",
    "\n",
    "from CanvasHacks.Definitions.journal import Journal\n",
    "\n",
    "# Import the Canvas class\n",
    "from canvasapi import Canvas\n",
    "# Newfangled repos\n",
    "from CanvasHacks.Repositories.students import StudentRepository\n",
    "\n",
    "# Grading\n",
    "from CanvasHacks.GradingHandlers.journal import JournalGrader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "make_test_selector()\n",
    "\n",
    "# force into testing harness\n",
    "test_course_id = 85210\n",
    "canvas = Canvas(environment.CONFIG.canvas_url_base, environment.CONFIG.canvas_token)\n",
    "course = canvas.get_course(test_course_id)\n",
    "environment.CONFIG.course = course "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What needs grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "make_assignment_chooser(Journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "course = environment.CONFIG.course\n",
    "courses = [course]\n",
    "\n",
    "# Initialize repositories\n",
    "studentRepo = StudentRepository(courses)\n",
    "studentRepo.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "Canvas doesn't allow partial credit on this sort of assignment it seems\n",
    "\n",
    "Appears that docx are not getting content extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Download and process all ungraded journal submissions\n",
    "\n",
    "    GET /api/v1/courses/:course_id/assignments/:assignment_id/submissions/:user_id \n",
    "    \n",
    " \n",
    " This version saves the downloaded data rather than holding in memory!\n",
    " \n",
    " \n",
    " ToDo\n",
    " \n",
    "     5/12/20: Had to set penalizer to no penality since credit no credit doesn't allow 50% penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as of CAN-40\n",
    "GRADING_LATE = True\n",
    "\n",
    "from CanvasHacks.Repositories.submissions import SubmissionRepository\n",
    "results = []\n",
    "\n",
    "for a in environment.CONFIG.assignments:\n",
    "    print(int(a[0]))\n",
    "    # canvas api object\n",
    "    assignment = course.get_assignment(int(a[0]))\n",
    "    # activity object to define the features \n",
    "    journal = Journal(**assignment.__dict__)\n",
    "    # Download submissions\n",
    "    subRepo = SubmissionRepository(assignment)\n",
    "    if GRADING_LATE:\n",
    "        # parse out already graded submissions\n",
    "        subRepo.data =[j for j in subRepo.data if j.grade != 'complete']\n",
    "\n",
    "    # shove the activity onto a sub repo so it will resemble\n",
    "    # a quizrepo for the grader\n",
    "    subRepo.activity = journal\n",
    "    # Initialize the package for results\n",
    "    store = DataStoreNew(journal)\n",
    "    # provisionally determine credit\n",
    "    grader = JournalGrader(subRepo)\n",
    "    store.results = grader.grade()\n",
    "\n",
    "    results.append(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read student work and check that properly categorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in results:\n",
    "    make_assignment_header(s)\n",
    "    make_consolidated_text_fields(s, studentRepo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make consolidated text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Todo: CAN-6 Fix this so only writes the files in results. currently writes from json storage\n",
    "from CanvasHacks.Widgets.ConsolidatedTextOutput import make_consolidated_text_file\n",
    "journal_folders = get_journal_folders()\n",
    "f = journal_folders[4]\n",
    "# make_consolidated_text_file(f, 'compiled-text.txt', studentRepo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload grades \n",
    "\n",
    " PUT /api/v1/courses/:course_id/assignments/:assignment_id/submissions/:user_id \n",
    " \n",
    " TODO: Add class identifier if have multiple classes\n",
    " \n",
    " TODO: Showing multiple copies of buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in results:\n",
    "    make_upload_button(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DON'T FORGET TO GO THROUGH GRADES ON CANVAS AND GIVE CREDIT WHERE MISSING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some light text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_WEEK = 2\n",
    "STOP_WEEK = 17\n",
    "IGNORE_FILE = \"%s/ignore.csv\" % environment.DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CanvasHacks.TextProcessing import make_wordbag\n",
    "from CanvasHacks.TextProcessing import WordFreq\n",
    "\n",
    "# Get all subfolder paths\n",
    "from CanvasHacks.JournalsFileTools import get_journal_folders, make_folder_list, calculate_journal_counts\n",
    "from CanvasHacks.JournalsFileTools import load_words_to_ignore, week_key_gen\n",
    "from CanvasHacks.JournalsTextTools import filter_out_terms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CanvasHacks.DataManagement import BagStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_folders = get_journal_folders()\n",
    "\n",
    "wcnt = calculate_journal_counts(journal_folders)\n",
    "wcnt   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_submissions_as_wordbags(filepath):\n",
    "    \"\"\"\n",
    "    Returns a list containing lists of words in each student's stored\n",
    "    submission\n",
    "    filepath: should be to a file with the structure of all-submissions.json\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        j = json.load(f)\n",
    "        return [make_wordbag(str(row['body'])) for row in j]\n",
    "\n",
    "\n",
    "# Load all content as wordbags\n",
    "journal_folders = get_journal_folders()\n",
    "exclude_list = load_words_to_ignore(IGNORE_FILE)\n",
    "\n",
    "store = BagStore()\n",
    "\n",
    "for folder_name in journal_folders:\n",
    "    fp = \"%s/all-submissions.json\" % folder_name\n",
    "    assignment_name = folder_name.split('/')[-1:][0]\n",
    "    print(\"loading {}\".format(assignment_name))\n",
    "    bags = load_all_submissions_as_wordbags(fp)\n",
    "    bags = [filter_out_terms(bag, exclude_list) for bag in bags]\n",
    "    store.add_assignment_bags(assignment_name, bags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "from CanvasHacks.VisualizationTools import draw_cloud, draw_cloud_from_freqs, draw_cumulative_freq, clearplot_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in store.assignment_names:\n",
    "    f = store.get_assignment_frequencies(name)\n",
    "    draw_cumulative_freq(f.freqDist, name)\n",
    "    # plot the wordcloud\n",
    "    draw_cloud_from_freqs(f.freqDist, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngram tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     51,
     55,
     62,
     70,
     74
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Previously in TextProcessingTools\n",
    "Created by adam on 11/11/15\n",
    "\"\"\"\n",
    "__author__ = 'adam'\n",
    "\n",
    "import nltk\n",
    "\n",
    "# This idiom is necessary. See https://github.com/nltk/nltk/issues/1516\n",
    "from nltk.metrics import association\n",
    "\n",
    "\n",
    "\n",
    "class NgramError(BaseException):\n",
    "    def __init__(self, processing_step):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            :param processing_step: String description of where error arose\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.kind = 'NgramProcessing'\n",
    "        self.identifier_type = 'String content'\n",
    "        self.step = processing_step\n",
    "#         ProcessingError.__init__(self, processing_step)\n",
    "\n",
    "class NgramGetter(object):\n",
    "    \"\"\"\n",
    "    Abstract parent class for extracting ngrams.\n",
    "\n",
    "    Attributes:\n",
    "        collocation_finder: One of the nltk's collocation finder tools (e.g., BigramCollocationFinder)\n",
    "        top_likelihood_ratio:\n",
    "        measurement_tool: One of nltk's measurement tools (e.g., nltk.collocations.BigramAssocMeasures)\n",
    "        modifiers: IModifier instantiating tool for modifying the text before calculating ngrams\n",
    "        ngrams: List of ngrams\n",
    "        raw_freq: Frequency distribution of ngrams\n",
    "        sorted_ngrams: List of tuples sorted by self.scored_ngrams\n",
    "        top_pmi: Variable number of n-grams with the highest Pointwise Mutual Information (i.e., which occur together\n",
    "        more often than would be expected)\n",
    "        word_bag: List of text to run\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.modifiers = []\n",
    "        self.ngram_filters = []\n",
    "        self.word_bag = []\n",
    "        self.ngrams = []\n",
    "        if not self.measurement_tool:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def add_modifier(self, iModifier):\n",
    "        assert(isinstance(iModifier, IModifier))\n",
    "        self.modifiers.append(iModifier)\n",
    "\n",
    "    def _run_modifiers(self):\n",
    "        \"\"\"\n",
    "        Calls the modifiers in sequence and stores the results back in word_bag\n",
    "        \"\"\"\n",
    "        for modifier in self.modifiers:\n",
    "            self.word_bag = [modifier.process(w) for w in self.word_bag]\n",
    "\n",
    "    def add_filter(self, iNgramFilter):\n",
    "        \"\"\"\n",
    "        Adds a filter to be run after the ngrams are created\n",
    "        :param iNgramFilter:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.ngram_filters.append(iNgramFilter)\n",
    "\n",
    "    def apply_filters(self):\n",
    "        for ftr in self.ngram_filters:\n",
    "            self.collocation_finder.apply_ngram_filter(ftr)\n",
    "\n",
    "    def process(self, word_bag, min_freq=3, get_top=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Runs any modifiers (stemmers, lemmatizers, etc) on the list of terms and\n",
    "        then extracts the ngrams\n",
    "\n",
    "        Args:\n",
    "            get_top: The cut off for ngrams to get stats for\n",
    "            min_freq: Integer of minimum number of appearances of ngram to extract\n",
    "            word_bag: List of strings to extract ngrams from. Should already be filtered.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _calculate_statistics(self, get_top=10, **kwargs):\n",
    "        \"\"\"\n",
    "                A number of measures are available to score collocations or other associations.\n",
    "        The arguments to measure functions are marginals of a contingency table,\n",
    "        in the bigram case (n_ii, (n_ix, n_xi), n_xx):\n",
    "                w1    ~w1\n",
    "             ------ ------\n",
    "         w2 | n_ii | n_oi | = n_xi\n",
    "             ------ ------\n",
    "        ~w2 | n_io | n_oo |\n",
    "             ------ ------\n",
    "             = n_ix        TOTAL = n_xx\n",
    "        We test their calculation using some known values presented\n",
    "        in Manning and Schutze's text and other papers.\n",
    "        Student's t: examples from Manning and Schutze 5.3.2\n",
    "        Arguments:\n",
    "            get_top: The cut off for ngrams to get stats for\n",
    "        \"\"\"\n",
    "        self.topPMI = self.collocation_finder.nbest(self.measurement_tool.pmi, get_top)\n",
    "        self.raw_freq = self.collocation_finder.score_ngrams(self.measurement_tool.raw_freq)\n",
    "        self.sorted_ngrams = [ngram for ngram, score in self.raw_freq]\n",
    "        self.top_likelihood_ratio = self.collocation_finder.nbest(self.measurement_tool.likelihood_ratio, get_top)\n",
    "\n",
    "\n",
    "class BigramGetter(NgramGetter):\n",
    "    \"\"\"\n",
    "    Extracts 2-grams from a word bag and calculates statistics\n",
    "    Attributes:\n",
    "        top_pmi: Variable number of n-grams with the highest Pointwise Mutual Information (i.e., which occur together\n",
    "        more often than would be expected)\n",
    "        top_likelihood_ratio:\n",
    "        raw_freq: Frequency distribution of ngrams\n",
    "        sorted_ngrams: List of tuples sorted by self.scored_ngrams\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.measurement_tool = association.BigramAssocMeasures()\n",
    "        NgramGetter.__init__(self)\n",
    "\n",
    "    def process(self, word_bag, min_freq=3, get_top=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            word_bag: List of strings\n",
    "        \"\"\"\n",
    "        assert(isinstance(word_bag, list))\n",
    "        self.collocation_finder = nltk.collocations.BigramCollocationFinder.from_words(word_bag)\n",
    "        self.collocation_finder.apply_freq_filter(min_freq)\n",
    "        self._calculate_statistics(get_top)\n",
    "\n",
    "class TrigramGetter(NgramGetter):\n",
    "    \"\"\"\n",
    "        Extracts 3-grams from a word bag and calculates statistics\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.measurement_tool = association.TrigramAssocMeasures()\n",
    "        NgramGetter.__init__(self)\n",
    "\n",
    "    def process(self, word_bag, min_freq=3, get_top=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            word_bag: List of strings\n",
    "        \"\"\"\n",
    "        assert(isinstance(word_bag, list))\n",
    "#         try:\n",
    "        self._run_modifiers()\n",
    "        self.collocation_finder = nltk.collocations.TrigramCollocationFinder.from_words(word_bag)\n",
    "        self.collocation_finder.apply_freq_filter(min_freq)\n",
    "        self._calculate_statistics(get_top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = []\n",
    "for name in store.assignment_names:\n",
    "    f = store.get_assignment_frequencies(name)\n",
    "    combined.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "bigrams = {}\n",
    "week_iter = week_key_gen()\n",
    "i = START_WEEK\n",
    "\n",
    "for name in store.assignment_names:\n",
    "    f = store.get_assignment_frequencies(name)\n",
    "    w = next(week_iter)\n",
    "\n",
    "    bg = BigramGetter()\n",
    "    bg.process(f.data)\n",
    "    #store the bigram object in our dict\n",
    "    bigrams[w] = bg\n",
    "\n",
    "    # reshape into a usable form for plotting\n",
    "    fs = FreqDist()\n",
    "    for s, freq in bg.raw_freq:\n",
    "        # make the string key and set the frequency\n",
    "        fs[\"%s %s\" % (s[0], s[1])] = freq\n",
    "\n",
    "    # plot the cumulative frequencies\n",
    "    draw_cumulative_freq(fs, i)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearplot_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top likelihood ratio\n",
    "def print_top_likelihood_ratios(ngrams):\n",
    "    week_iter = week_key_gen()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            week = next(week_iter)\n",
    "            print(week)\n",
    "            [print(b) for b in ngrams[week].top_likelihood_ratio]\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "def print_top_PMI(ngrams):\n",
    "    week_iter = week_key_gen()\n",
    "    print(\"Top PMI\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            week = next(week_iter)\n",
    "            print(week)\n",
    "            [print(b) for b in ngrams[week].topPMI]\n",
    "        except StopIteration:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_likelihood_ratios(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_PMI(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = {}\n",
    "week_iter = week_key_gen()\n",
    "i = START_WEEK\n",
    "\n",
    "\n",
    "for name in store.assignment_names:\n",
    "    f = store.get_assignment_frequencies(name)\n",
    "    w = next(week_iter)\n",
    "\n",
    "    bg = TrigramGetter()\n",
    "        \n",
    "    bg.process(f.data)\n",
    "    #store the bigram object in our dict\n",
    "    trigrams[w] = bg\n",
    "\n",
    "    # reshape into a usable form for plotting\n",
    "    fs = FreqDist()\n",
    "    for s, freq in bg.raw_freq:\n",
    "        # make the string key and set the frequency\n",
    "        fs[\"%s %s %s\" % (s[0], s[1], s[2])] = freq\n",
    "\n",
    "    # plot the cumulative frequencies\n",
    "    draw_cumulative_freq(fs, i)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         w = next(week_iter)\n",
    "        \n",
    "#         bg = TrigramGetter()\n",
    "#         bg.process(combined[w])\n",
    "#         #store the trigram object in our dict\n",
    "#         trigrams[w] = bg\n",
    "\n",
    "#         # reshape into a usable form for plotting\n",
    "#         fs = FreqDist()\n",
    "#         for s, freq in bg.raw_freq:\n",
    "#             # make the string key and set the frequency\n",
    "#             fs[\"%s %s %s\" % (s[0], s[1], s[2])] = freq\n",
    "\n",
    "#         # plot the cumulative frequencies\n",
    "#         draw_cumulative_freq({w : fs}, i)\n",
    "#         i += 1\n",
    "#     except StopIteration:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearplot_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_likelihood_ratios(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_PMI(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "GRADING_LATE = True\n",
    "\n",
    "from CanvasHacks.Repositories.submissions import SubmissionRepository\n",
    "results = []\n",
    "\n",
    "for a in environment.CONFIG.assignments:\n",
    "    # canvas api object\n",
    "    assignment = course.get_assignment(int(a[0]))\n",
    "    # activity object to define the features \n",
    "    journal = Journal(**assignment.attributes)\n",
    "    # Download submissions\n",
    "    subRepo = SubmissionRepository(assignment)\n",
    "    store = DataStoreNew(journal)\n",
    "    # provisionally determine credit\n",
    "    store.results = GT.new_determine_journal_credit(journal, subRepo)\n",
    "    if GRADING_LATE:\n",
    "        store.results = [j for j in store.results if j[0].grade != 'complete']\n",
    "\n",
    "    results.append(store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Master: This handles downloading all assignments which need grading and \n",
    "# determines whether to give them credit. It does not yet upload grades\n",
    "results = []\n",
    "\n",
    "for course_id in environment.CONFIG.course_ids:\n",
    "    print('course', course_id)\n",
    "    for assignment_id, name in environment.CONFIG.assignments:\n",
    "        store = DataStore(assignment_id=assignment_id, assignment_name=name, course_id=course_id)\n",
    "\n",
    "        print(\"Processing {}\".format(name))\n",
    "        # make folder to save data\n",
    "        folder = journal_folder_name(name, course_id)\n",
    "        create_folder(folder)\n",
    "        \n",
    "        # download student submissions \n",
    "        response = PT.get_submissions(course_id, assignment_id)\n",
    "        print(\"{} responses received\".format(len(response)))\n",
    "#         print(response)\n",
    "        store.submissions = PT.process_response(response, folder)\n",
    "        \n",
    "        # save a copy \n",
    "        PT.save_submission_json(store.submissions, folder)\n",
    "        \n",
    "        # give credit for non-empty submissions\n",
    "        c = GT.determine_credit(store.submissions)\n",
    "        \n",
    "        # stow the results in our data object\n",
    "        store.credit = c['credit']\n",
    "        store.no_credit = c['nocredit']\n",
    "        store.print_counts()\n",
    "        \n",
    "        # Add the now full-of-data object to our results list\n",
    "        results.append(store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d =pd.DataFrame([{'a' :2, 'b': 3}, {'a' :12, 'b': 13}])\n",
    "for i, r in d.iterrows():\n",
    "    assert(isinstance(r, pd.Series))\n",
    "    print(r.a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canv-env",
   "language": "python",
   "name": "canv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
