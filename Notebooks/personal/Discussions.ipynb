{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ideas for how to make this work__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://canvas.instructure.com/doc/api/peer_reviews.html\n",
    "\n",
    "https://canvasapi.readthedocs.io/en/latest/course-ref.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "%cd ~/Dropbox/CanvasHacks\n",
    "\n",
    "#Plotting \n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "from canvasapi import Canvas\n",
    "\n",
    "from CanvasHacks import environment\n",
    "\n",
    "# API access\n",
    "# from CanvasHacks.RequestTools import *\n",
    "# from CanvasHacks.UrlTools import *\n",
    "# import CanvasHacks.DownloadProcessingTools as PT\n",
    "from CanvasHacks.Api.UploadGradeTools import make_upload_button\n",
    "\n",
    "# Filesystem\n",
    "from CanvasHacks.Files.FileTools import makeDataFileIterator, create_folder\n",
    "from CanvasHacks.TimeTools import getDateForMakingFileName\n",
    "\n",
    "# Configuration\n",
    "from CanvasHacks.Definitions.unit import Unit\n",
    "from CanvasHacks.Definitions.discussion import DiscussionReview, DiscussionForum\n",
    "from CanvasHacks.Configuration import InteractiveConfiguration\n",
    "\n",
    "# Grading\n",
    "# from CanvasHacks.GradingTools.nonempty import receives_credit, CreditForNonEmptyOLD #grade_credit_no_credit\n",
    "from CanvasHacks.GradingHandlers.discussion import DiscussionForumGrader\n",
    "\n",
    "# Models\n",
    "from CanvasHacks.Models.student import Student\n",
    "from CanvasHacks.Models.review_association import ReviewAssociation\n",
    "\n",
    "# Notifications\n",
    "# from CanvasHacks.PeerReviewed.Notifications import make_conversation_data, notify_student\n",
    "# from CanvasHacks.PeerReviewed.Notifications import make_prompt_and_response, make_notice, send_message_to_reviewers\n",
    "from CanvasHacks.Models.student import get_first_name\n",
    "\n",
    "# Repos\n",
    "from CanvasHacks.Repositories.DataManagement import DataStore\n",
    "from CanvasHacks.Repositories.discussions import DiscussionRepository\n",
    "from CanvasHacks.Repositories.students import StudentRepository\n",
    "# from CanvasHacks.Repositories.codes import AccessCodeRepo\n",
    "from CanvasHacks.Repositories.reviewer_associations import assign_reviewers, AssociationRepository\n",
    "\n",
    "# Storage\n",
    "from CanvasHacks.DAOs.sqlite_dao import SqliteDAO\n",
    "\n",
    "\n",
    "# Widgets\n",
    "from CanvasHacks.Widgets.ConsolidatedTextOutput import make_assignment_header, make_consolidated_text_fields\n",
    "from CanvasHacks.Widgets.InputFields import make_course_ids_input, make_canvas_token_input, make_canvas_url_input, make_general_reset_button\n",
    "from CanvasHacks.Widgets.AssignmentSelection import make_discussion_chooser\n",
    "from CanvasHacks.Widgets.LiveSelection import make_test_selector\n",
    "from CanvasHacks.Widgets.AssignmentSelection import make_unit_chooser, make_selection_button\n",
    "\n",
    "\n",
    "import inspect\n",
    "def look_inside(obj):\n",
    "    print(inspect.getmembers(obj, lambda a:not(inspect.isroutine(a))))\n",
    "\n",
    "from tests.factories.PeerReviewedFactories import discussion_entry_factory\n",
    "\n",
    "LOC = '{}/Box Sync/TEACHING/Phil 305 Business ethics/Phil305 S20'.format(environment.ROOT)# placeholder for where the access codes are stored\n",
    "SEMESTER_NAME = 'S20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "make_test_selector()\n",
    "make_unit_chooser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "canvas = environment.CONFIG.canvas\n",
    "course = environment.CONFIG.course\n",
    "unit = environment.CONFIG.unit\n",
    "\n",
    "# codeRepo = AccessCodeRepo(ACCESS_CODES_FP, environment.CONFIG.unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = course.get_quiz( rev.quiz_id )\n",
    "q.access_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = unit.review\n",
    "rev.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CanvasHacks.Widgets.DiscussionControls import discussion_run_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discussion_run_button()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle sending posts to reviewers (as of CAN-44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CanvasHacks.SkaaSteps.SendForumPostsToReviewer import SendForumPostsToReviewer\n",
    "\n",
    "SEND = False\n",
    "POST_THRESHOLD = 2\n",
    "step = SendForumPostsToReviewer(environment.CONFIG.course, environment.CONFIG.unit, send=SEND, post_threshold=POST_THRESHOLD)\n",
    "\n",
    "step._load_step()\n",
    "# step.run() #download=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(step.work_repo.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(step.work_repo.filter_by_count(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2\n",
    "students_to_keep = [sid for sid, cnt in step.work_repo.post_counts if cnt >= threshold]\n",
    "[s for s in filter(lambda x: x['student_id'] in students_to_keep, step.work_repo.data)]\n",
    " # data.groupby('student_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step.work_repo.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step.activity.is_discussion_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step._assign_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step.associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assocs = step.dao.session.query(ReviewAssociation).filter(ReviewAssociation.activity_id == unit.discussion_review.id).all()\n",
    "len(assocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step.send=True\n",
    "step.associations = assocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step._message_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle sending results to posters (as of CAN-44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CanvasHacks.SkaaSteps.SendDiscussionReviewToPoster import SendDiscussionReviewToPoster\n",
    "SEND = False\n",
    "step = SendDiscussionReviewToPoster(environment.CONFIG.course, environment.CONFIG.unit, send=SEND)\n",
    "\n",
    "step._load_step(rest_timeout=5)\n",
    "# step.run(download=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step._assign_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step.send = True\n",
    "step._message_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step.dao.session.query(ReviewAssociation).filter(ReviewAssociation.activity_id == unit.discussion_review.id).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVERYTHING BELOW NEEDS TO BE UPDATED TO WORK WITH CAN-44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher's review and grading\n",
    "\n",
    "__Todo__:\n",
    "\n",
    "    Update all methods to run on each repository in repos to allow for handling multiple classes/discussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "make_discussion_chooser(environment.CONFIG.course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.CONFIG.unit.get_activity_by_id(797742)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.CONFIG.discussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# If we haven't already gotten the discussion posts, do so for the selected discussions\n",
    "\n",
    "try:\n",
    "    if len(repos)>0:\n",
    "        print(\"repos already populated\")\n",
    "\n",
    "except NameError:\n",
    "    repos=[]\n",
    "    for topic_id, name in environment.CONFIG.discussions:\n",
    "        discussion_obj = environment.CONFIG.unit.get_discussion_by_topic_id(topic_id)\n",
    "        print(\"Downloading posts for {}\", name)\n",
    "        discussionRepo = DiscussionRepository(course=environment.CONFIG.course, activity=discussion_obj)\n",
    "        discussionRepo.download()\n",
    "        repos.append(discussionRepo)\n",
    "\n",
    "discussionRepo = repos[0]\n",
    "\n",
    "studentRepo = StudentRepository(environment.CONFIG.course)\n",
    "studentRepo.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View posts\n",
    "\n",
    "__Todo:__ \n",
    "\n",
    "    Only works right now for one discussion at a time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discussionRepo.post_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display for teacher\n",
    "\n",
    "__Todo:__ \n",
    "    \n",
    "    Add buttons etc for modifying whether receives credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_template = \"\"\"\n",
    "\\n ============== {student_name}  {student_id} ============== \\n\n",
    "{posts}\n",
    "\\n ========================================================== \\n\n",
    "\"\"\"\n",
    "\n",
    "# Collect each students' posts into one text block\n",
    "# but don't display yet. This way the same results can either be displayed to teacher\n",
    "# with identifiers or used to send to student reviewer\n",
    "for_grading = []\n",
    "for sid in discussionRepo.student_ids:\n",
    "#     posts = [post_template.format(text=p) for p in discussionRepo.get_student_posts(sid)]\n",
    "    \n",
    "    posts = discussionRepo.get_student_posts(sid)\n",
    "    posts = \"\".join(posts)\n",
    "    j = { 'student_name' : studentRepo.get_student_name(sid),\n",
    "    'student_id' : sid,\n",
    "    'posts' : posts\n",
    "    }\n",
    "    for_grading.append(j)\n",
    "\n",
    "len(for_grading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in for_grading:\n",
    "    print(student_template.format(**d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign provisional grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_posts_required = 1\n",
    "\n",
    "grader = DiscussionForumGrader(discussionRepo, num_posts_required)\n",
    "totals = grader.grade()\n",
    "len(totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review provisional grades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out how many students got what pct credit\n",
    "tts = pd.Series([pct_credit for student_id, pct_credit in totals])\n",
    "sns.countplot(tts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in results:\n",
    "    make_assignment_header(s)\n",
    "    make_consolidated_text_fields(s, studentRepo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successes = 0; errors = 0\n",
    "for student_id, pct_credit in totals:\n",
    "    if student_id != environment.CONFIG.excluded_users:\n",
    "        try:\n",
    "            r = discussionRepo.upload_student_grade(student_id, pct_credit)\n",
    "            successes += 1\n",
    "        except AttributeError as e:\n",
    "            print(student_id, pct_credit, e)\n",
    "            errors += 1\n",
    "\n",
    "print(\"Successfully uploaded grades for {} students\".format(successes))\n",
    "print(\"Error uploading grades for {} students\".format(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from CanvasHacks.Repositories.quizzes import QuizRepository, ReviewRepository\n",
    "from CanvasHacks.QuizReportFileTools import sort_frames_by_age, get_newest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "make_unit_chooser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_discussion_chooser(environment.CONFIG.course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "create_folder(unit.discussion_review.folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load review results (from file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_newest_data(environment.CONFIG.unit.discussion_review)\n",
    "\n",
    "surveyRepo = ReviewRepository(environment.CONFIG.unit.discussion_review, environment.CONFIG.course)\n",
    "surveyRepo.data = d\n",
    "surveyRepo.set_question_columns(surveyRepo.data)\n",
    "# fix_forgot_answers(surveyRepo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load things\n",
    "\n",
    "if environment.CONFIG.is_test:\n",
    "    # testing: in memory db\n",
    "    dao = SqliteDAO()\n",
    "    print(\"Connected to testing db\")\n",
    "else:\n",
    "    db_filepath = \"{}/{}-Unit-{}-discussion-review.db\".format( environment.LOG_FOLDER, SEMESTER_NAME, environment.CONFIG.unit_number)\n",
    "    # real: file db\n",
    "    dao = SqliteDAO(db_filepath)\n",
    "    dao.initialize_db_file()\n",
    "    print(\"Connected to REAL db\")\n",
    "\n",
    "associationRepo = AssociationRepository(dao, environment.CONFIG.unit.discussion_review)\n",
    "\n",
    "# If we haven't already gotten the discussion posts, do so for the selected discussions\n",
    "try:\n",
    "    if len(repos)>0:\n",
    "        pass\n",
    "except NameError:\n",
    "    repos=[]\n",
    "    for topic_id, name in environment.CONFIG.discussions:\n",
    "        print(\"Downloading posts for {}\", name)\n",
    "        discussionRepo = DiscussionRepository(environment.CONFIG.course, topic_id)\n",
    "        discussionRepo.download()\n",
    "        repos.append(discussionRepo)\n",
    "        print(topic_id)\n",
    "\n",
    "discussionRepo = repos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect distributions etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from CanvasHacks.VisualizationTools import rotate_x_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = nrows=round(len(surveyRepo.multiple_choice_names)/2)\n",
    "fig, axes = plt.subplots(ncols=2, nrows=rows, figsize=(12,15))\n",
    "order = [l for l in environment.LIKERT_PLOT_ORDER if l != 'Forgot']\n",
    "\n",
    "row=0; col=0\n",
    "for c in surveyRepo.multiple_choice_names:\n",
    "    title = c.split(':')[1][:65]\n",
    "    g = sns.countplot(d[c], order=order, palette='plasma', ax=axes[row, col])\n",
    "    g.set_xlabel('')\n",
    "    axes[row, col].set_title(title)\n",
    "    rotate_x_labels(axes[row, col])\n",
    "    if col == 1:\n",
    "        row += 1\n",
    "        col = 0\n",
    "    else:\n",
    "        col += 1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check posts flagged as inconsistent with policies and not receiving full credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "CONCERNING = ['Disagree', 'Strongly disagree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyRepo.make_question_selection_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_for_review = []\n",
    "data = surveyRepo.data.set_index('student_id')[surveyRepo.selected]\n",
    "\n",
    "# rows in which the reviewer is expressing a concern about the performance\n",
    "# of the student whom they reviewed\n",
    "of_concern = data[data[surveyRepo.selected].isin(CONCERNING)].dropna(how='all')\n",
    "\n",
    "# Combine the posts, ratings, and student info\n",
    "for rid, row in of_concern.iterrows():\n",
    "    aid = associationRepo.get_assessee(environment.CONFIG.unit.discussion_review, rid)\n",
    "    p ={ 'author': aid,\n",
    "     'reviewer': rid,\n",
    "     'ratings' : row,\n",
    "     'posts': discussionRepo.get_student_posts(aid)\n",
    "    }\n",
    "    posts_for_review.append(p)\n",
    "\n",
    "print(\"Loaded posts and ratings for {} reviewees\".format(len(posts_for_review)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "posts_for_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "## Send feedback to person reviewed\n",
    "posts_for_send = []\n",
    "# This time we are getting everyone\n",
    "data = surveyRepo.data.set_index('student_id')\n",
    "\n",
    "# Combine the posts, ratings, and student info\n",
    "for rid, row in data.iterrows():\n",
    "    aid = associationRepo.get_assessee(environment.CONFIG.unit.discussion_review, rid)\n",
    "    p ={ 'author': aid,\n",
    "     'reviewer': rid,\n",
    "     'ratings' : row,\n",
    "     'posts': discussionRepo.get_student_posts(aid)\n",
    "    }\n",
    "    _for_send.append(p)\n",
    "\n",
    "print(\"Loaded posts and ratings for {} reviewees\".format(len(_for_send)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "posts = []\n",
    "problems = []\n",
    "for sid, submission in discussionRepo.submissions.items():\n",
    "    for entry in submission.discussion_entries:\n",
    "        try:\n",
    "            posts.append( (entry['user_id'], entry['user_name'], entry['message']) )\n",
    "        except:\n",
    "            problems.append(entry)\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_discussion_entries(course, topic_id):\n",
    "    \"\"\"Returns a list of discussion objects. \n",
    "        Objects look something like:\n",
    "        {'id': 2132485, 'user_id': 169155, \n",
    "        'parent_id': None, 'created_at': '2020-01-16T23:01:53Z', \n",
    "        'updated_at': '2020-01-16T23:01:53Z', 'rating_count': None,\n",
    "        'rating_sum': None, 'user_name': 'Test Student', \n",
    "        'message': '<p>got em</p>', 'user': {'id': 169155, \n",
    "        'display_name': 'Test Student',\n",
    "        'avatar_image_url': 'https://canvas.csun.edu/images/messages/avatar-50.png',\n",
    "        'html_url': 'https://canvas.csun.edu/courses/85210/users/169155',\n",
    "        'pronouns': None, 'fake_student': True}, \n",
    "        'read_state': 'unread', 'forced_read_state': False, \n",
    "        'discussion_id': 737847, 'course_id': 85210}\n",
    "    \"\"\"\n",
    "    discussion = course.get_discussion_topic(topic_id)\n",
    "    # result is lazy loaded, so iterate through it\n",
    "    return [e for e in discussion.get_topic_entries()]\n",
    " \n",
    "\n",
    "def parse_discussion_results(results):\n",
    "    \"\"\"Returns a list of tuples of all dicussion posts for the topic\n",
    "    Format:\n",
    "        [ ( user_id, text )]\n",
    "        \"\"\"\n",
    "    return [( e.user_id, e.message ) for e in results]\n",
    "    \n",
    "#     print(e.attributes)\n",
    "#     look_inside(e.attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "sub = discussionRepo.submissions[22946]\n",
    "sub.discussion_entries\n",
    "\n",
    "def parse_posts_from_submission(submission):\n",
    "    for entry in submisson.discussion_entries:\n",
    "        self.posts.append( (entry.user_id, entry.user_name, entry.message) )\n",
    "\n",
    "    return (subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def assign_grades(discussion_repo, num_posts_required):\n",
    "    credit_per_post = 100 / num_posts_required\n",
    "\n",
    "    grades = [ \n",
    "    # ( sid, percent credit)\n",
    "    ]\n",
    "\n",
    "    for p in discussion_repo.data:\n",
    "    #     print(post, grade_credit_no_credit(post))\n",
    "#         credit_per_post\n",
    "        pct_credit = credit_per_post if grade_credit_no_credit(p['text']) else 0\n",
    "        grades.append( (p['student_id'], pct_credit) )\n",
    "\n",
    "    # sum them up and put in list for upload\n",
    "    totals = []\n",
    "    sids = list(set([s[0] for s in grades]))\n",
    "    for sid in sids:\n",
    "        t = sum([s[1] for s in grades])\n",
    "        t = 100 if t > 100 else t\n",
    "        totals.append( ( sid,  t)) \n",
    "    return totals\n",
    "\n",
    "# totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Provide to reviewer (old)\n",
    "if environment.CONFIG.is_test:\n",
    "    # testing: in memory db\n",
    "    dao = SqliteDAO()\n",
    "    print(\"Connected to testing db\")\n",
    "else:\n",
    "    db_filepath = \"{}/{}-Unit-{}-discussion-review.db\".format( environment.LOG_FOLDER, SEMESTER_NAME, environment.CONFIG.unit_number)\n",
    "    # real: file db\n",
    "    dao = SqliteDAO(db_filepath)\n",
    "    dao.initialize_db_file()\n",
    "    print(\"Connected to REAL db\")\n",
    "\n",
    "associationRepo = AssociationRepository(dao, environment.CONFIG.unit.discussion_review)\n",
    "\n",
    "# all students who submitted the assignment\n",
    "# submitters = [169908, 169955, 169957]\n",
    "submitters = discussionRepo.student_ids\n",
    "\n",
    "# Assign reviewers to each submitter and store in db\n",
    "associationRepo.assign_reviewers( submitters)\n",
    "\n",
    "if not environment.CONFIG.is_test:\n",
    "    # Make audit file\n",
    "    review_audit = []\n",
    "    for rev in associationRepo.get_associations(unit.discussion_review):\n",
    "        print(rev.assessor_id, rev.assessee_id)\n",
    "        assessor = studentRepo.get_student(rev.assessor_id)\n",
    "        assessee = studentRepo.get_student(rev.assessee_id)\n",
    "        print(assessor)\n",
    "\n",
    "        review_audit.append({\n",
    "            'activity' : unit.discussion_review.name,\n",
    "            'assessor_name' : assessor.short_name,\n",
    "            'assessor_sis_id': assessor.sis_user_id,\n",
    "            'assessor_canvas_id': assessor.id,\n",
    "            'assessee_name' : assessee.short_name,\n",
    "            'assessee_sis_id': assessee.sis_user_id,\n",
    "            'assessee_canvas_id': assessee.id,\n",
    "            'timestamp': datetime.datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "    review_audit = pd.DataFrame(review_audit)\n",
    "\n",
    "    fp = \"{}/{}-Unit{}-peer review assignments.csv\".format(environment.LOG_FOLDER, getDateForMakingFileName(), environment.CONFIG.unit )\n",
    "    review_audit.to_csv(fp)\n",
    "    print(\"Audit file saved to {}\".format(fp))\n",
    "    # review_audit\n",
    "\n",
    "SEND = False\n",
    "# SEND = True\n",
    "\n",
    "# make sure access code set on activity before running until CAN-32 is done!\n",
    "\n",
    "send_message_to_reviewers(associationRepo, studentRepo, discussionRepo, unit.discussion_review, SEND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rubrics\n",
    " GET /api/v1/courses/:course_id/rubrics/:id \n",
    " \n",
    " __this is all wasted time. Rubrics can only be used by instructor not given to students for peer review__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_id = 568253\n",
    "assign = course.get_assignment(assign_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will need submissions to look up graded student info\n",
    "subs_repo = SubmissionRepository(assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [r for r in assign.get_peer_reviews()]\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = [ s for s in assign.get_submissions()]\n",
    "subs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubrics = [r for r in course.get_rubrics()]\n",
    "rubrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ 'assessments', 'graded_assessments', \n",
    "                                       'peer_assessments', 'associations', \n",
    "                                       'assignment_associations', \n",
    "                                       'course_associations', 'account_associations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric = course.get_rubric(14141, style='full', include=[  'graded_assessments'])\n",
    "rubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_id = \n",
    "artifact_id = 22191947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric.rubric_association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rubric.assessments\n",
    "\n",
    "Actual graded rubrics\n",
    "\n",
    "{'id': 239043,\n",
    "  'rubric_id': 14141,\n",
    "  'rubric_association_id': 28259,\n",
    "  \n",
    "  Total score\n",
    "  'score': 10.0,\n",
    "  'artifact_id': 22191947,\n",
    "  'artifact_type': 'Submission',\n",
    "  'assessment_type': 'grading',\n",
    "  \n",
    "  Person grading\n",
    "  'assessor_id': 6417,\n",
    "  'artifact_attempt': 2,\n",
    "  \n",
    "  'data': [{'id': None,\n",
    "    'points': 2.0,\n",
    "    'criterion_id': '_9091',\n",
    "    'learning_outcome_id': None,\n",
    "    'description': 'No details',\n",
    "    'comments_enabled': True,\n",
    "    'comments': ''},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need for peer review graded discussion posts (CAN-16)\n",
    "\n",
    "- grading student\n",
    "\n",
    "- graded student\n",
    "\n",
    "- all scores\n",
    "\n",
    "- all comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_graded_student_id(rubric_assessment, submissions):\n",
    "    submission_id = rubric_assessment['artifact_id']\n",
    "    for s in submissions:\n",
    "        if s.id == submission_id:\n",
    "            return s.user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_graded_student_id(rubric.assessments[0], subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_id = rubric.assessments[0]['rubric_association']['association_id']\n",
    "print(assign_id)\n",
    "assign = course.get_assignment(assign_id)\n",
    "# assign.get_submission(22191947)\n",
    "for s in assign.get_submissions():\n",
    "    print(s)\n",
    "    \n",
    "    \n",
    "assign.get_submission(169155)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric.assessments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true,
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# # TEST = True\n",
    "# TEST = False\n",
    "# SEMESTER_NAME = 'S20'\n",
    "\n",
    "# if TEST:\n",
    "#     environment.CONFIG.set_test()\n",
    "# # environment.CONFIG.set_live()\n",
    "# ACCESS_CODES_FP = \"{}/{}-assignment-access-codes.xlsx\".format(LOC, SEMESTER_NAME)\n",
    "# COURSE_ID = environment.CONFIG.course_ids[0]\n",
    "# COURSE_ID\n",
    "\n",
    "PROF_ID = 6417\n",
    "\n",
    "# Test data\n",
    "test_course_id = 85210\n",
    "\n",
    "main_quiz = 165098\n",
    "review_quiz = 165820\n",
    "meta_review = 165821\n",
    "\n",
    "url = 'https://canvas.csun.edu/api/v1/courses/85210/assignments/{}/submissions'\n",
    "\n",
    "# last semester data\n",
    "prev_course_id = 62657\n",
    "prev_quiz = 151633\n",
    "\n",
    "COURSE_ID = test_course_id\n",
    "# COURSE_ID = prev_course_id\n",
    "# QUIZ_ID = prev_quiz\n",
    "\n",
    "TEST_STUDENT_ID = 168439\n",
    "\n",
    "\n",
    "\n",
    "topic_id = 737847\n",
    "graded_topic_id = 768729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true,
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def make_question_selection_buttons(repo):\n",
    "    \"\"\"Given a repository containing a dataframe and a \n",
    "    list of names in question_names, this will allow to select\n",
    "    which questions are used for things\"\"\"\n",
    "    buttons = []\n",
    "    for q in repo.question_names:\n",
    "        b = make_selection_button(q, q, repo.get_selections, repo.select, repo.deselect, '100%' )\n",
    "        buttons.append(b)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "download_url = parse_download_url(response)\n",
    "\n",
    "response_content_for_testing = b'{\"id\":91464,\"report_type\":\"student_analysis\",\"readable_type\":\"Student Analysis\",\"includes_all_versions\":false,\"includes_sis_ids\":true,\"generatable\":true,\"anonymous\":false,\"url\":\"https://canvas.csun.edu/api/v1/courses/85210/quizzes/165820/reports/91464\",\"progress_url\":\"https://canvas.csun.edu/api/v1/progress/335965\",\"created_at\":\"2019-12-27T01:45:29Z\",\"updated_at\":\"2019-12-27T01:55:54Z\",\"file\":{\"id\":7868563,\"uuid\":\"VZNHEVLsfBZt2IJYCvkBdmM2x5LfqIBVjXoRmDVo\",\"folder_id\":null,\"display_name\":\"Quiz1-review Survey Student Analysis Report.csv\",\"filename\":\"quiz_student_analysis_report.csv\",\"upload_status\":\"success\",\"content-type\":\"text/csv\",\"url\":\"https://canvas.csun.edu/files/7868563/download?download_frd=1\\\\u0026verifier=VZNHEVLsfBZt2IJYCvkBdmM2x5LfqIBVjXoRmDVo\",\"size\":132,\"created_at\":\"2019-12-27T01:55:54Z\",\"updated_at\":\"2019-12-27T01:55:54Z\",\"unlock_at\":null,\"locked\":false,\"hidden\":false,\"lock_at\":null,\"hidden_for_user\":false,\"thumbnail_url\":null,\"modified_at\":\"2019-12-27T01:55:54Z\",\"mime_class\":\"file\",\"media_entry_id\":null,\"locked_for_user\":false},\"quiz_id\":165820}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "#     'quiz_report': [{\n",
    "#         'report_type': 'student_analysis',\n",
    "#     }],\n",
    "    \"include\": [\"progress\", \"file\"]\n",
    "}\n",
    "\n",
    "# This report url works properly!!!!!!!!!!!!!!!!\n",
    "report_url = 'https://canvas.csun.edu/api/v1/courses/85210/quizzes/165820/reports/91464'\n",
    "# Make the request \n",
    "# We can't use the usual function since we don't want response.json()\n",
    "head = { 'Authorization': 'Bearer {}'.format( environment.CONFIG.canvas_token ) }\n",
    "response = requests.get( report_url, headers=make_request_header(), json=data )\n",
    "\n",
    "print('response was ', response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# report_url = 'https://canvas.csun.edu/api/v1/courses/85210/quizzes/165820/reports/91464'\n",
    "\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canv-env",
   "language": "python",
   "name": "canv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
